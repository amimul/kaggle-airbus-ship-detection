{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F2 metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.ndimage import label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementations found online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F2 by Rares Barbantan: https://www.kaggle.com/raresbarbantan/f2-metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliar code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(img_true, img_pred):\n",
    "    i = np.sum((img_true*img_pred) >0)\n",
    "    u = np.sum((img_true + img_pred) >0) + 0.0000000000000000001  # avoid division by zero\n",
    "    return i/u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F2 metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "\n",
    "def f2_rares(masks_true, masks_pred):\n",
    "    # a correct prediction on no ships in image would have F2 of zero (according to formula),\n",
    "    # but should be rewarded as 1\n",
    "    if np.sum(masks_true) == np.sum(masks_pred) == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    f2_total = 0\n",
    "    for t in thresholds:\n",
    "        tp,fp,fn = 0,0,0\n",
    "        ious = {}\n",
    "        for i,mt in enumerate(masks_true):\n",
    "            found_match = False\n",
    "            for j,mp in enumerate(masks_pred):\n",
    "                miou = iou(mt, mp)\n",
    "                ious[100*i+j] = miou # save for later\n",
    "                if miou >= t:\n",
    "                    found_match = True\n",
    "            if not found_match:\n",
    "                fn += 1\n",
    "                \n",
    "        for j,mp in enumerate(masks_pred):\n",
    "            found_match = False\n",
    "            for i, mt in enumerate(masks_true):\n",
    "                miou = ious[100*i+j]\n",
    "                if miou >= t:\n",
    "                    found_match = True\n",
    "                    break\n",
    "            if found_match:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        f2 = (5*tp)/(5*tp + 4*fn + fp)\n",
    "        f2_total += f2\n",
    "    \n",
    "    return f2_total/len(thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F2 by Iafoss: https://www.kaggle.com/iafoss/unet34-submission-tta-0-699-new-public-lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2_iafoss(true, pred):\n",
    "    n_th = 10\n",
    "    b = 4\n",
    "    thresholds = [0.5 + 0.05*i for i in range(n_th)]\n",
    "    n_masks = len(true)\n",
    "    n_pred = len(pred)\n",
    "    ious = []\n",
    "    score = 0\n",
    "    for mask in true:\n",
    "        buf = []\n",
    "        for p in pred: buf.append(iou(mask, p))\n",
    "        ious.append(buf)\n",
    "    for t in thresholds:   \n",
    "        tp, fp, fn = 0, 0, 0\n",
    "        for i in range(n_masks):\n",
    "            match = False\n",
    "            for j in range(n_pred):\n",
    "                if ious[i][j] > t: match = True\n",
    "            if not match: fn += 1\n",
    "        \n",
    "        for j in range(n_pred):\n",
    "            match = False\n",
    "            for i in range(n_masks):\n",
    "                if ious[i][j] > t: match = True\n",
    "            if match: tp += 1\n",
    "            else: fp += 1\n",
    "        score += ((b+1)*tp)/((b+1)*tp + b*fn + fp)       \n",
    "    return score/n_th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F2 by Mark Ayzenshtadt: https://www.kaggle.com/markup/f2-metric-optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2_mark(masks_true, masks_pred):\n",
    "    if np.sum(masks_true) == 0:\n",
    "        return float(np.sum(masks_pred) == 0)\n",
    "    \n",
    "    ious = []\n",
    "    mp_idx_found = []\n",
    "    for mt in masks_true:\n",
    "        for mp_idx, mp in enumerate(masks_pred):\n",
    "            if mp_idx not in mp_idx_found:\n",
    "                #print(\"mt, mp:\", mt, mp)\n",
    "                cur_iou = iou(mt,mp)\n",
    "                if cur_iou > 0.5:\n",
    "                    ious.append(cur_iou)\n",
    "                    mp_idx_found.append(mp_idx)\n",
    "                    break\n",
    "    f2_total = 0\n",
    "    for th in thresholds:\n",
    "        tp = sum([iou > th for iou in ious])\n",
    "        fn = len(masks_true) - tp\n",
    "        fp = len(masks_pred) - tp\n",
    "        f2_total += (5*tp)/(5*tp + 4*fn + fp)\n",
    "\n",
    "    return f2_total/len(thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " [[[1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [1. 1. 1. 1. 1.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]]]\n",
      "Predictions:\n",
      " [[[1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]]]\n",
      "F2 Rares:\n",
      " 0.6\n",
      "F2 Mark:\n",
      " 0.6\n",
      "F2 Iafoss:\n",
      " 0.6\n"
     ]
    }
   ],
   "source": [
    "target = np.zeros((2, 5, 5))\n",
    "target[0, :, 0] = 1\n",
    "target[0, 2, :] = 1\n",
    "target[1, :, 2] = 1\n",
    "prediction = np.zeros((2, 5, 5))\n",
    "prediction[0, :, 0] = 1\n",
    "prediction[1, :, 2] = 1\n",
    "\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Predictions:\\n\", prediction)\n",
    "print(\"F2 Rares:\\n\", f2_rares(target, prediction))\n",
    "print(\"F2 Mark:\\n\", f2_mark(target, prediction))\n",
    "print(\"F2 Iafoss:\\n\", f2_iafoss(target, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot_np(y, num_classes=None, axis=0, dtype=\"float32\"):\n",
    "    \"\"\"Converts a class numpy.ndarray (integers) to a one hot numpy.ndarray.\n",
    "\n",
    "    Modified from: https://github.com/keras-team/keras/blob/master/keras/utils/np_utils.py#L9\n",
    "\n",
    "    Arguments:\n",
    "        y (numpy.ndarray): array of integer values in the range\n",
    "            [0, num_classes - 1] to be one hot encoded.\n",
    "        num_classes (int, optional): total number of classes. If set to None,\n",
    "            num_classes = max(y) + 1. Default: None.\n",
    "        axis (int, optional): the axis where the one hot classes are encoded.\n",
    "            E.g. when set to 1 and the size of y is (5, 5) the output is\n",
    "            (5, num_classes, 5). Default: 0.\n",
    "        dtype (torch.dtype, optional): the output data type, as a string (float32,\n",
    "            float64, int32...). Default: float32.\n",
    "\n",
    "    Returns:\n",
    "        A one hot representation of the input numpy.ndarray.\n",
    "    \"\"\"\n",
    "    y = np.array(y, dtype=\"int\")\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    elif np.amax(y) > num_classes - 1 or np.amin(y) < 0:\n",
    "        raise ValueError(\"y values outside range [0, {}]\".format(num_classes - 1))\n",
    "\n",
    "    input_shape = y.shape\n",
    "    y = y.ravel()\n",
    "    n = y.shape[0]\n",
    "    output_shape = list(input_shape)\n",
    "    output_shape.append(num_classes)\n",
    "    axis_order = list(range(len(input_shape)))\n",
    "    axis_order.insert(axis, -1)\n",
    "\n",
    "    categorical = np.zeros((n, num_classes), dtype=dtype)\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "\n",
    "    return np.transpose(categorical, axis_order)\n",
    "\n",
    "def split_ships(input, max_ships=30, on_max_error=False):\n",
    "    \"\"\"Takes a mask of ships and splits them into different individual masks.\n",
    "\n",
    "    Uses a structuring element to define connected blobs (ships in this case),\n",
    "    scipy.ndimage.label does all the work.\n",
    "    See: https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.label.html\n",
    "\n",
    "    Arguments:\n",
    "        input (numpy.ndarray): the mask of ships to split with size (H, W).\n",
    "        min_size(int, optional): only blobs above this size in pixels are labeled as\n",
    "            ships, essentially noise removal. Default: 18.\n",
    "        max_ships_error (int, optional): maximum number of ships allowed in a single\n",
    "            image. If surpassed, a ValueError is raised. Default: 100.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: the masks of individual ships with size (n, H, W), where n is the\n",
    "        number of ships. If there are no ships, returns a array of size (1, H, W) filled\n",
    "        with zeros.\n",
    "\n",
    "    \"\"\"\n",
    "    # The background is also labeled\n",
    "    max_blobs = max_ships + 1\n",
    "\n",
    "    # No blobs/ships, return empty mask\n",
    "    if np.sum(input) == 0:\n",
    "        return np.expand_dims(input, 0)\n",
    "\n",
    "    # Labels blobs/ships in the image\n",
    "    labeled_ships, num_ships = label(input)\n",
    "    if num_ships > max_blobs:\n",
    "        if on_max_error:\n",
    "            raise ValueError(\n",
    "                \"too many ships found {}, expect a maximum of {}\".format(\n",
    "                    num_ships, max_ships\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            # Compute the size of each labeled blob and get the corresponding size so\n",
    "            # that only max_blobs remain\n",
    "            blob_sizes = np.bincount(labeled_ships.ravel())\n",
    "            sorted_blob_sizes = np.sort(blob_sizes)\n",
    "            min_size = sorted_blob_sizes[-max_blobs]\n",
    "            too_small = blob_sizes < min_size\n",
    "\n",
    "            # Labels that are below min_size are set to background, the remaining\n",
    "            # objects are relabeled\n",
    "            mask = too_small[labeled_ships]\n",
    "            labeled_ships[mask] = 0\n",
    "            labeled_ships, num_ships = label(labeled_ships)\n",
    "\n",
    "    # For convenience, each ship is isolated in an image. Achieving this is equivalent\n",
    "    # to converting labeled_ships into its one hot form and then removing the first\n",
    "    # channel which is the background\n",
    "    out = to_onehot_np(labeled_ships, num_ships + 1)[1:]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " [[0 1 1 0 1 1 1 0 1 1 1 0 0 1 1 0]\n",
      " [1 0 1 1 0 0 0 0 1 1 1 1 0 1 0 0]\n",
      " [1 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1]\n",
      " [1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 0]\n",
      " [0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1]\n",
      " [0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0]\n",
      " [1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 1]\n",
      " [1 1 0 1 1 1 0 0 1 0 0 0 1 0 0 0]\n",
      " [1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 0]\n",
      " [1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1]\n",
      " [1 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0]\n",
      " [0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0]\n",
      " [0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1]\n",
      " [1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 1]\n",
      " [0 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1]\n",
      " [1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 0]]\n",
      "Predictions:\n",
      " [[1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1]\n",
      " [0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 0]\n",
      " [1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1]\n",
      " [1 1 1 1 1 0 0 0 1 0 0 1 0 1 1 1]\n",
      " [1 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0]\n",
      " [1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1]\n",
      " [1 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0]\n",
      " [0 1 1 1 0 0 0 0 1 0 0 0 0 1 1 0]\n",
      " [1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 1]\n",
      " [1 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1]\n",
      " [0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0]\n",
      " [0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1]\n",
      " [1 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0]\n",
      " [1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1]\n",
      " [1 1 0 0 0 0 1 1 1 1 1 0 1 1 0 0]\n",
      " [1 0 1 1 1 1 0 0 0 1 0 0 1 0 1 1]]\n",
      "Split ships target:\n",
      " (5, 16, 16)\n",
      "\n",
      "\n",
      "valueError raised:\n",
      " too many ships found 20, expect a maximum of 5\n"
     ]
    }
   ],
   "source": [
    "target = np.random.randint(2, size=(16, 16))\n",
    "prediction = np.random.randint(2, size=(16, 16))\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Predictions:\\n\", prediction)\n",
    "print(\"Split ships target:\\n\", split_ships(target, max_ships=5).shape)\n",
    "print()\n",
    "print()\n",
    "try:\n",
    "    split_ships(prediction, max_ships=5, on_max_error=True)\n",
    "except ValueError as e:\n",
    "    print(\"valueError raised:\\n\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " [[1. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 1. 1.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [1. 0. 1. 0. 0.]]\n",
      "Predictions:\n",
      " [[0 0 1 1 1 0]\n",
      " [2 2 0 0 3 3]\n",
      " [0 0 0 0 3 3]]\n",
      "Split ships target:\n",
      " [[[1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 1. 1.]\n",
      "  [0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0.]]]\n",
      "\n",
      "\n",
      "Split ships prediction:\n",
      " [[[0. 0. 1. 1. 1. 0.]\n",
      "  [0. 0. 0. 0. 1. 1.]\n",
      "  [0. 0. 0. 0. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      "  [1. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "target = np.zeros((5, 5))\n",
    "target[:, 0] = 1\n",
    "target[2, 2:] = 1\n",
    "target[:, 2] = 1\n",
    "prediction = np.array([[0, 0, 1, 1, 1, 0], [2, 2, 0, 0, 3, 3], [0, 0, 0, 0, 3, 3]])\n",
    "\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Predictions:\\n\", prediction)\n",
    "print(\"Split ships target:\\n\", split_ships(target))\n",
    "print()\n",
    "print()\n",
    "print(\"Split ships prediction:\\n\", split_ships(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score(\n",
    "    prediction_masks, target_masks, beta=2, thresholds=np.arange(0.5, 1, 0.05)\n",
    "):\n",
    "    # If the target is empty return 1 if the prediction is also empty; otherwise\n",
    "    # return 0\n",
    "    if np.sum(target_masks) == 0:\n",
    "        return float(np.sum(prediction_masks) == 0)\n",
    "\n",
    "    iou_arr = []\n",
    "    pred_idx_found = []\n",
    "    for target in target_masks:\n",
    "        for pred_idx, pred in enumerate(prediction_masks):\n",
    "            # Check if this prediction mask has already been matched to a target mask\n",
    "            if pred_idx not in pred_idx_found:\n",
    "                curr_iou = iou(pred, target)\n",
    "                if curr_iou > np.min(thresholds):\n",
    "                    iou_arr.append(curr_iou)\n",
    "                    # Matched a prediction with a target, remember the index so we don't\n",
    "                    # match it to another target mask\n",
    "                    pred_idx_found.append(pred_idx)\n",
    "                    break\n",
    "\n",
    "    # F score computation\n",
    "    fscore_total, tp, fn, fp = 0, 0, 0, 0\n",
    "    beta_sq = beta * beta\n",
    "    iou_np = np.array(iou_arr)\n",
    "    for th in thresholds:\n",
    "        tp = np.sum(iou_np > th)\n",
    "        fp = len(prediction_masks) - tp\n",
    "        fn = len(target_masks) - tp\n",
    "        fscore_total += (1 + beta_sq) * tp / ((1 + beta_sq) * tp + beta_sq * fn + fp)\n",
    "\n",
    "    return fscore_total / len(thresholds)\n",
    "\n",
    "\n",
    "class AirbusFScoreApprox():    \n",
    "    def __init__(\n",
    "        self,\n",
    "        beta=2,\n",
    "        thresholds=np.arange(0.5, 1, 0.05),\n",
    "        max_ships=30,\n",
    "        name=\"fscore_approx\",\n",
    "    ):\n",
    "        self.thresholds = thresholds\n",
    "        self.beta = beta\n",
    "        self.max_ships = max_ships\n",
    "        self.fscore_history = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.fscore_history = []\n",
    "\n",
    "    def add(self, predicted, target):\n",
    "        # Parameter check\n",
    "        if predicted.size() != target.size():\n",
    "            raise ValueError(\n",
    "                \"size mismatch, {} != {}\".format(predicted.size(), target.size())\n",
    "            )\n",
    "        elif tuple(predicted.unique(sorted=True)) not in [(0, 1), (0,), (1,)]:\n",
    "            raise ValueError(\"predicted values are not binary\")\n",
    "        elif tuple(target.unique(sorted=True)) not in [(0, 1), (0,), (1,)]:\n",
    "            raise ValueError(\"target values are not binary\")\n",
    "\n",
    "        # Flatten the tensor and convert to numpy\n",
    "        predicted = predicted.squeeze().cpu().numpy()\n",
    "        target = target.squeeze().cpu().numpy()\n",
    "\n",
    "        for p, t in zip(predicted, target):\n",
    "            # Try to split the segmentation mask in into one mask per ship\n",
    "            # This process might raise an error if too many ships are found, especially\n",
    "            # during the early stages of training.\n",
    "            predicted_ships = split_ships(p, max_ships=self.max_ships)\n",
    "\n",
    "            # Note that here we want to fail if too many ships are found, it should\n",
    "            # never happen\n",
    "            target_ships = split_ships(t, max_ships=self.max_ships, on_max_error=True)\n",
    "            score = f_score(\n",
    "                predicted_ships,\n",
    "                target_ships,\n",
    "                beta=self.beta,\n",
    "                thresholds=self.thresholds,\n",
    "            )\n",
    "            self.fscore_history.append(score)\n",
    "\n",
    "    def value(self):\n",
    "        if len(self.fscore_history) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return np.mean(self.fscore_history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 1., 1., 1.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "Predictions:\n",
      " tensor([[[1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 1., 1.],\n",
      "         [1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "F2:\n",
      " 0.85\n"
     ]
    }
   ],
   "source": [
    "target = torch.zeros((2, 5, 5))\n",
    "target[0, :, 0] = 1\n",
    "target[0, 2, 2:] = 1\n",
    "target[1, :, 2] = 1\n",
    "prediction = torch.zeros((2, 5, 5))\n",
    "prediction[0, :, 0] = 1\n",
    "prediction[0, 2, 3:] = 1\n",
    "prediction[1, :, 2] = 1\n",
    "\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Predictions:\\n\", prediction)\n",
    "f2 = AirbusFScoreApprox()\n",
    "f2.add(prediction, target)\n",
    "print(\"F2:\\n\", f2.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.3 ms ± 463 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "target = torch.zeros((8, 384, 384))\n",
    "prediction = torch.zeros((8, 384, 384))\n",
    "%timeit f2.add(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Airbus",
   "language": "python",
   "name": "airbus-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
