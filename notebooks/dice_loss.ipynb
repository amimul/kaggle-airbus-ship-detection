{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary dice loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDiceWithLogitsLoss(nn.Module):\n",
    "    \"\"\"Computes the Sørensen–Dice loss with logits for binary data.\n",
    "\n",
    "    Dice_coefficient = 2 * intersection(X, Y) / (|X| + |Y|)\n",
    "    where, X and Y are sets of binary data, in this case, predictions and targets.\n",
    "    |X| and |Y| are the cardinalities of the corresponding sets.\n",
    "\n",
    "    The optimizer minimizes the loss function therefore:\n",
    "    Dice_loss = -Dice_coefficient\n",
    "    (min(-x) = max(x))\n",
    "\n",
    "    See: https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "\n",
    "    Arguments:\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "            'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n",
    "            'mean': the sum of the output will be divided by the number of\n",
    "            elements in the output, 'sum': the output will be summed. Default: 'mean'\n",
    "        eps (float, optional): small value to avoid division by zero. Default: 1e-6.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, reduction=\"mean\", eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        if reduction.lower() == \"none\":\n",
    "            self.reduction_op = None\n",
    "        elif reduction.lower() == \"mean\":\n",
    "            self.reduction_op = torch.mean\n",
    "        elif reduction.lower() == \"sum\":\n",
    "            self.reduction_op = torch.sum\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"expected one of ('none', 'mean', 'sum'), got {}\".format(reduction)\n",
    "            )\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.size() != target.size():\n",
    "            raise ValueError(\n",
    "                \"size mismatch, {} != {}\".format(input.size(), target.size())\n",
    "            )\n",
    "        elif target.unique(sorted=True).tolist() not in [[0, 1], [0], [1]]:\n",
    "            raise ValueError(\"target values are not binary\")\n",
    "\n",
    "        input = input.view(-1)\n",
    "        target = target.view(-1)\n",
    "\n",
    "        # Dice = 2 * intersection(X, Y) / (|X| + |Y|)\n",
    "        # X and Y are sets of binary data, in this case, probabilities and targets\n",
    "        # |X| and |Y| are the cardinalities of the corresponding sets\n",
    "        probabilities = torch.sigmoid(input)\n",
    "        num = torch.sum(target * probabilities)\n",
    "        den_t = torch.sum(target)\n",
    "        den_p = torch.sum(probabilities)\n",
    "        loss = -2 * (num / (den_t + den_p + self.eps))\n",
    "\n",
    "        if self.reduction_op is not None:\n",
    "            return self.reduction_op(loss)\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " tensor([1.])\n",
      "Model out:\n",
      " tensor([2.2000])\n",
      "BD Loss:\n",
      " tensor(-0.9475)\n",
      "BCE Loss:\n",
      " tensor(0.1051)\n"
     ]
    }
   ],
   "source": [
    "loss = BinaryDiceWithLogitsLoss()\n",
    "\n",
    "target = torch.Tensor([1])\n",
    "out = torch.Tensor([2.2])\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Model out:\\n\", out)\n",
    "print(\"BD Loss:\\n\", loss.forward(out, target))\n",
    "print(\"BCE Loss:\\n\", nn.functional.binary_cross_entropy_with_logits(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " tensor([1.])\n",
      "Model out:\n",
      " tensor([3.4300])\n",
      "BD Loss:\n",
      " tensor(-0.9841)\n",
      "BCE Loss:\n",
      " tensor(0.0319)\n"
     ]
    }
   ],
   "source": [
    "target = torch.Tensor([1])\n",
    "out = torch.Tensor([3.43])\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Model out:\\n\", out)\n",
    "print(\"BD Loss:\\n\", loss.forward(out, target))\n",
    "print(\"BCE Loss:\\n\", nn.functional.binary_cross_entropy_with_logits(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " tensor([1., 0.])\n",
      "Model out:\n",
      " tensor([100., -50.])\n",
      "Loss:\n",
      " tensor(-1.0000)\n",
      "BCE Loss:\n",
      " tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "target = torch.Tensor([1, 0])\n",
    "out = torch.Tensor([100, -50])\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Model out:\\n\", out)\n",
    "print(\"Loss:\\n\", loss.forward(out, target))\n",
    "print(\"BCE Loss:\\n\", nn.functional.binary_cross_entropy_with_logits(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " tensor([1., 0., 0., 0., 1.])\n",
      "Model out:\n",
      " tensor([ -5.0000,  -2.5000,  -6.0000, -10.0000,  -2.0000])\n",
      "Loss:\n",
      " tensor(-0.1142)\n",
      "BCE Loss:\n",
      " tensor(1.4430)\n"
     ]
    }
   ],
   "source": [
    "target = torch.Tensor([1, 0, 0, 0, 1])\n",
    "out = torch.Tensor([-5, -2.5, -6, -10, -2])\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Model out:\\n\", out)\n",
    "print(\"Loss:\\n\", loss.forward(out, target))\n",
    "print(\"BCE Loss:\\n\", nn.functional.binary_cross_entropy_with_logits(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " torch.Size([2, 5, 5])\n",
      "Model out:\n",
      " torch.Size([2, 5, 5])\n",
      "Loss:\n",
      " tensor(-0.5891)\n",
      "BCE Loss:\n",
      " tensor(1.3547)\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(2, (2, 5, 5))\n",
    "out = torch.randint(2, (2, 5, 5)) * 3.44\n",
    "print(\"Target:\\n\", target.size())\n",
    "print(\"Model out:\\n\", out.size())\n",
    "print(\"Loss:\\n\", loss.forward(out, target))\n",
    "print(\"BCE Loss:\\n\", nn.functional.binary_cross_entropy_with_logits(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " torch.Size([2, 5, 5])\n",
      "Model out:\n",
      " torch.Size([2, 5, 5])\n",
      "Loss:\n",
      " tensor(-1.)\n",
      "BCE Loss:\n",
      " tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(2, (2, 5, 5)).float()\n",
    "out = (target * 100) - 50\n",
    "print(\"Target:\\n\", target.size())\n",
    "print(\"Model out:\\n\", out.size())\n",
    "print(\"Loss:\\n\", loss.forward(out, target))\n",
    "print(\"BCE Loss:\\n\", nn.functional.binary_cross_entropy_with_logits(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871 ms ± 12 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(2, (10, 2048, 2048))\n",
    "out = target * 100\n",
    "%timeit loss.forward(out, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class dice loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceWithLogitsLoss(nn.Module):\n",
    "    \"\"\"Computes the Sørensen–Dice loss with logits.\n",
    "\n",
    "    Dice_coefficient = 2 * intersection(X, Y) / (|X| + |Y|)\n",
    "    where, X and Y are sets of binary data, in this case, predictions and targets.\n",
    "    |X| and |Y| are the cardinalities of the corresponding sets.\n",
    "\n",
    "    The optimizer minimizes the loss function therefore:\n",
    "    Dice_loss = -Dice_coefficient\n",
    "    (min(-x) = max(x))\n",
    "\n",
    "    See: https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "\n",
    "    Arguments:\n",
    "        num_classes (int): number of classes in the classification problem\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "            'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n",
    "            'mean': the sum of the output will be divided by the number of\n",
    "            elements in the output, 'sum': the output will be summed. Default: 'mean'\n",
    "        eps (float, optional): small value to avoid division by zero. Default: 1e-6.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, reduction=\"mean\", eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        if reduction.lower() == \"none\":\n",
    "            self.reduction_op = None\n",
    "        elif reduction.lower() == \"mean\":\n",
    "            self.reduction_op = torch.mean\n",
    "        elif reduction.lower() == \"sum\":\n",
    "            self.reduction_op = torch.sum\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"expected one of ('none', 'mean', 'sum'), got {}\".format(reduction)\n",
    "            )\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim() != 2 and input.dim() != 4:\n",
    "            raise ValueError(\n",
    "                \"expected input of size 4 or 2, got {}\".format(input.dim())\n",
    "            )\n",
    "\n",
    "        if target.dim() != 1 and target.dim() != 3:\n",
    "            raise ValueError(\n",
    "                \"expected target of size 3 or 1, got {}\".format(target.dim())\n",
    "            )\n",
    "\n",
    "        if input.dim() == 4 and target.dim() == 3:\n",
    "            reduce_dims = (0, 3, 2)\n",
    "        elif input.dim() == 2 and target.dim() == 1:\n",
    "            reduce_dims = 0\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"expected target dimension {} for input dimension {}, got {}\".format(\n",
    "                    input.dim() - 1, input.dim(), target.dim()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        target_onehot = to_onehot(target, input.size(1))\n",
    "        probabilities = nn.functional.softmax(input, 1)\n",
    "\n",
    "        # Dice = 2 * intersection(X, Y) / (|X| + |Y|)\n",
    "        # X and Y are sets of binary data, in this case, probabilities and targets\n",
    "        # |X| and |Y| are the cardinalities of the corresponding sets\n",
    "        num = torch.sum(target_onehot * probabilities, dim=reduce_dims)\n",
    "        den_t = torch.sum(target_onehot, dim=reduce_dims)\n",
    "        den_p = torch.sum(probabilities, dim=reduce_dims)\n",
    "        loss = -2 * (num / (den_t + den_p + self.eps))\n",
    "\n",
    "        if self.reduction_op is not None:\n",
    "            return self.reduction_op(loss)\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(tensor, num_classes):    \n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    onehot = torch.zeros(tensor.size(0), num_classes, *tensor.size()[2:])\n",
    "    onehot.scatter_(1, tensor, 1)\n",
    "    \n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " tensor([1])\n",
      "Model out:\n",
      " tensor([[-100.,  100., -100.,  -50.]])\n",
      "Loss:\n",
      " tensor(-0.2500)\n"
     ]
    }
   ],
   "source": [
    "loss = DiceWithLogitsLoss()\n",
    "\n",
    "target = torch.Tensor([1]).long()\n",
    "out = torch.Tensor([[-100, 100, -100, -50]]).float()\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Model out:\\n\", out)\n",
    "print(\"Loss:\\n\", loss.forward(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " tensor([1, 0, 0])\n",
      "Model out:\n",
      " tensor([[-100.,  100., -100.,  -50.],\n",
      "        [-100., -100., -100.,   50.],\n",
      "        [ 100., -100., -100.,  -50.]])\n",
      "Loss:\n",
      " tensor(-0.4167)\n"
     ]
    }
   ],
   "source": [
    "target = torch.Tensor([1, 0, 0]).long()\n",
    "out = torch.Tensor([[-100, 100, -100, -50], [-100, -100, -100, 50], [100, -100, -100, -50]]).float()\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Model out:\\n\", out)\n",
    "print(\"Loss:\\n\", loss.forward(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " torch.Size([2, 5, 5])\n",
      "Model out:\n",
      " torch.Size([2, 3, 5, 5])\n",
      "Loss:\n",
      " tensor(-0.3683)\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(3, (2, 5, 5)).long()\n",
    "out = torch.randint(3, (2, 5, 5)).long()\n",
    "out = to_onehot(out, 3) * 100\n",
    "print(\"Target:\\n\", target.size())\n",
    "print(\"Model out:\\n\", out.size())\n",
    "print(\"Loss:\\n\", loss.forward(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " torch.Size([2, 5, 5])\n",
      "Model out:\n",
      " torch.Size([2, 3, 5, 5])\n",
      "Loss:\n",
      " tensor(-1.)\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(3, (2, 5, 5)).long()\n",
    "out = to_onehot(target, 3).float() * 100\n",
    "print(\"Target:\\n\", target.size())\n",
    "print(\"Model out:\\n\", out.size())\n",
    "print(\"Loss:\\n\", loss.forward(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.28 s ± 109 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(3, (10, 2048, 2048)).long()\n",
    "out = to_onehot(target, 3).float() * 100\n",
    "%timeit loss.forward(out, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Airbus",
   "language": "python",
   "name": "airbus-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
