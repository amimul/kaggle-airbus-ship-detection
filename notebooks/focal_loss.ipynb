{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary focal loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryFocalWithLogitsLoss(nn.Module):\n",
    "    \"\"\"Computes the focal loss with logits for binary data.\n",
    "\n",
    "    The Focal Loss is designed to address the one-stage object detection scenario in\n",
    "    which there is an extreme imbalance between foreground and background classes during\n",
    "    training (e.g., 1:1000). Focal loss is defined as:\n",
    "\n",
    "    FL = alpha(1 - p)^gamma * CE(p, y)\n",
    "    where p are the probabilities, after applying the Softmax layer to the logits,\n",
    "    alpha is a balancing parameter, gamma is the focusing parameter, and CE(p, y) is the\n",
    "    cross entropy loss. When gamma=0 and alpha=1 the focal loss equals cross entropy.\n",
    "\n",
    "    See: https://arxiv.org/abs/1708.02002\n",
    "\n",
    "    Arguments:\n",
    "        num_classes (int): number of classes in the classification problem\n",
    "        gamma (float, optional): focusing parameter. Default: 2.\n",
    "        alpha (float, optional): balancing parameter. Default: 0.25.\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "            'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n",
    "            'mean': the sum of the output will be divided by the number of\n",
    "            elements in the output, 'sum': the output will be summed. Default: 'mean'\n",
    "        eps (float, optional): small value to avoid division by zero. Default: 1e-6.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gamma=2, alpha=0.25, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if reduction.lower() == \"none\":\n",
    "            self.reduction_op = None\n",
    "        elif reduction.lower() == \"mean\":\n",
    "            self.reduction_op = torch.mean\n",
    "        elif reduction.lower() == \"sum\":\n",
    "            self.reduction_op = torch.sum\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"expected one of ('none', 'mean', 'sum'), got {}\".format(reduction)\n",
    "            )        \n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        if input.size() != target.size():\n",
    "            raise ValueError(\n",
    "                \"size mismatch, {} != {}\".format(input.size(), target.size())\n",
    "            )\n",
    "        elif target.unique(sorted=True).tolist() not in [[0, 1], [0], [1]]:\n",
    "            raise ValueError(\"target values are not binary\")\n",
    "            \n",
    "        input = input.view(-1)\n",
    "        target = target.view(-1)\n",
    "        \n",
    "        # Following the paper: probabilities = probabilities if y=1; otherwise, probabilities = 1-probabilities\n",
    "        probabilities = torch.sigmoid(input)\n",
    "        probabilities = torch.where(target == 1, probabilities, 1 - probabilities)\n",
    "        \n",
    "        # Compute the loss\n",
    "        focal = self.alpha * (1 - probabilities).pow(self.gamma)\n",
    "        bce = nn.functional.binary_cross_entropy_with_logits(input, target, reduction=\"none\")\n",
    "        loss = focal * bce\n",
    "\n",
    "        if self.reduction_op is not None:\n",
    "            return self.reduction_op(loss)\n",
    "        else:\n",
    "            return loss\n",
    "        \n",
    "    def forward_heng(self, logits, labels):\n",
    "        \"\"\"https://www.kaggle.com/c/carvana-image-masking-challenge/discussion/39951\"\"\"\n",
    "        probs  = torch.sigmoid(logits)\n",
    "\n",
    "        w_pos = torch.pow((1-probs), self.gamma)\n",
    "        w_neg = torch.pow((probs), self.gamma)\n",
    "        weights = (labels==1).float()*w_pos + (labels==0).float()*w_neg\n",
    "\n",
    "        inputs   = logits.view (-1)\n",
    "        targets = labels.view(-1)\n",
    "        weights   = weights.view (-1)\n",
    "\n",
    "        loss = weights * inputs.clamp(min=0) - weights * inputs * targets + weights * torch.log(1 + torch.exp(-inputs.abs()))\n",
    "        loss = loss.sum() / weights.sum()\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def forward_adrien(self, input, target):\n",
    "        \"\"\"https://becominghuman.ai/investigating-focal-and-dice-loss-for-the-kaggle-2018-data-science-bowl-65fb9af4f36c\"\"\"\n",
    "        # Inspired by the implementation of binary_cross_entropy_with_logits\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\".format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        # This formula gives us the log sigmoid of 1-p if y is 0 and of p if y is 1\n",
    "        invprobs = nn.functional.logsigmoid(-input * (target * 2 - 1))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following losses should match very closely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " tensor([1.])\n",
      "Model out:\n",
      " tensor([2.2000])\n",
      "BF Loss x100:\n",
      " tensor(0.1046)\n",
      "BF Loss Heng x100:\n",
      " tensor(10.5083)\n",
      "Loss Adrien x100:\n",
      " tensor(0.1046)\n",
      "BCE Loss:\n",
      " tensor(0.1051)\n"
     ]
    }
   ],
   "source": [
    "loss = BinaryFocalWithLogitsLoss(alpha=1)\n",
    "\n",
    "target = torch.Tensor([1])\n",
    "out = torch.Tensor([2.2])\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Model out:\\n\", out)\n",
    "print(\"BF Loss x100:\\n\", loss.forward(out, target) * 100)\n",
    "print(\"BF Loss Heng x100:\\n\", loss.forward_heng(out, target) * 100)\n",
    "print(\"Loss Adrien x100:\\n\", loss.forward_adrien(out, target) * 100)\n",
    "print(\"BCE Loss:\\n\", nn.functional.binary_cross_entropy_with_logits(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " tensor([1.])\n",
      "Model out:\n",
      " tensor([3.4300])\n",
      "BF Loss x1000:\n",
      " tensor(0.0314)\n",
      "BF Loss Heng x1000:\n",
      " tensor(31.8735)\n",
      "Loss Adrien x1000:\n",
      " tensor(0.0314)\n",
      "BCE Loss:\n",
      " tensor(0.0319)\n"
     ]
    }
   ],
   "source": [
    "target = torch.Tensor([1])\n",
    "out = torch.Tensor([3.43])\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Model out:\\n\", out)\n",
    "print(\"BF Loss x1000:\\n\", loss.forward(out, target) * 1000)\n",
    "print(\"BF Loss Heng x1000:\\n\", loss.forward_heng(out, target) * 1000)\n",
    "print(\"Loss Adrien x1000:\\n\", loss.forward_adrien(out, target) * 1000)\n",
    "print(\"BCE Loss:\\n\", nn.functional.binary_cross_entropy_with_logits(out, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " tensor([1., 0.])\n",
      "Model out:\n",
      " tensor([100., -50.])\n",
      "BF Loss:\n",
      " tensor(0.)\n",
      "BF Loss Heng:\n",
      " tensor(0.)\n",
      "Loss Adrien:\n",
      " tensor(0.)\n",
      "BCE Loss:\n",
      " tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "target = torch.Tensor([1, 0])\n",
    "out = torch.Tensor([100, -50])\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Model out:\\n\", out)\n",
    "print(\"BF Loss:\\n\", loss.forward(out, target))\n",
    "print(\"BF Loss Heng:\\n\", loss.forward_heng(out, target))\n",
    "print(\"Loss Adrien:\\n\", loss.forward_adrien(out, target))\n",
    "print(\"BCE Loss:\\n\", nn.functional.binary_cross_entropy_with_logits(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " tensor([1., 0., 0., 0., 1.])\n",
      "Model out:\n",
      " tensor([ -5.0000,  -2.5000,  -6.0000, -10.0000,  -2.0000])\n",
      "BF Loss:\n",
      " tensor(1.3181)\n",
      "BF Loss Heng:\n",
      " tensor(3.7272)\n",
      "Loss Adrien:\n",
      " tensor(1.3181)\n",
      "BCE Loss:\n",
      " tensor(1.4430)\n"
     ]
    }
   ],
   "source": [
    "target = torch.Tensor([1, 0, 0, 0, 1])\n",
    "out = torch.Tensor([-5, -2.5, -6, -10, -2])\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Model out:\\n\", out)\n",
    "print(\"BF Loss:\\n\", loss.forward(out, target))\n",
    "print(\"BF Loss Heng:\\n\", loss.forward_heng(out, target))\n",
    "print(\"Loss Adrien:\\n\", loss.forward_adrien(out, target))\n",
    "print(\"BCE Loss:\\n\", nn.functional.binary_cross_entropy_with_logits(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " torch.Size([2, 5, 5])\n",
      "Model out:\n",
      " torch.Size([2, 5, 5])\n",
      "BF Loss:\n",
      " tensor(1.1296)\n",
      "BF Loss Heng:\n",
      " tensor(2.6541)\n",
      "Loss Adrien:\n",
      " tensor(1.1296)\n",
      "BCE Loss:\n",
      " tensor(1.4632)\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(2, (2, 5, 5))\n",
    "out = torch.randint(2, (2, 5, 5)) * 3.44\n",
    "print(\"Target:\\n\", target.size())\n",
    "print(\"Model out:\\n\", out.size())\n",
    "print(\"BF Loss:\\n\", loss.forward(out, target))\n",
    "print(\"BF Loss Heng:\\n\", loss.forward_heng(out, target))\n",
    "print(\"Loss Adrien:\\n\", loss.forward_adrien(out, target))\n",
    "print(\"BCE Loss:\\n\", nn.functional.binary_cross_entropy_with_logits(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " torch.Size([2, 5, 5])\n",
      "Model out:\n",
      " torch.Size([2, 5, 5])\n",
      "BF Loss:\n",
      " tensor(0.)\n",
      "BF Loss Heng:\n",
      " tensor(0.)\n",
      "Loss Adrien:\n",
      " tensor(0.)\n",
      "BCE Loss:\n",
      " tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(2, (2, 5, 5)).float()\n",
    "out = (target * 100) - 50\n",
    "print(\"Target:\\n\", target.size())\n",
    "print(\"Model out:\\n\", out.size())\n",
    "print(\"BF Loss:\\n\", loss.forward(out, target))\n",
    "print(\"BF Loss Heng:\\n\", loss.forward_heng(out, target))\n",
    "print(\"Loss Adrien:\\n\", loss.forward_adrien(out, target))\n",
    "print(\"BCE Loss:\\n\", nn.functional.binary_cross_entropy_with_logits(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4 s ± 254 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(2, (5, 2048, 2048))\n",
    "out = target * 100\n",
    "%timeit loss.forward(out, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalWithLogitsLoss(nn.Module):\n",
    "    \"\"\"Computes the focal loss with logits.\n",
    "\n",
    "    The Focal Loss is designed to address the one-stage object detection scenario in\n",
    "    which there is an extreme imbalance between foreground and background classes during\n",
    "    training (e.g., 1:1000). Focal loss is defined as:\n",
    "\n",
    "    FL = alpha(1 - p)^gamma * CE(p, y)\n",
    "    where p are the probabilities, after applying the Softmax layer to the logits,\n",
    "    alpha is a balancing parameter, gamma is the focusing parameter, and CE(p, y) is the\n",
    "    cross entropy loss. When gamma=0 and alpha=1 the focal loss equals cross entropy.\n",
    "\n",
    "    See: https://arxiv.org/abs/1708.02002\n",
    "\n",
    "    Arguments:\n",
    "        gamma (float, optional): focusing parameter. Default: 2.\n",
    "        alpha (float, optional): balancing parameter. Default: 0.25.\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "            'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n",
    "            'mean': the sum of the output will be divided by the number of\n",
    "            elements in the output, 'sum': the output will be summed. Default: 'mean'\n",
    "        eps (float, optional): small value to avoid division by zero. Default: 1e-6.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gamma=2, alpha=0.25, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if reduction.lower() == \"none\":\n",
    "            self.reduction_op = None\n",
    "        elif reduction.lower() == \"mean\":\n",
    "            self.reduction_op = torch.mean\n",
    "        elif reduction.lower() == \"sum\":\n",
    "            self.reduction_op = torch.sum\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"expected one of ('none', 'mean', 'sum'), got {}\".format(reduction)\n",
    "            )\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim() == 4:\n",
    "            input = input.permute(0, 2, 3, 1)\n",
    "            input = input.contiguous().view(-1, input.size(-1))\n",
    "        elif input.dim() != 2:\n",
    "            raise ValueError(\n",
    "                \"expected input of size 4 or 2, got {}\".format(input.dim())\n",
    "            )\n",
    "\n",
    "        if target.dim() == 3:\n",
    "            target = target.contiguous().view(-1)\n",
    "        elif target.dim() != 1:\n",
    "            raise ValueError(\n",
    "                \"expected target of size 3 or 1, got {}\".format(target.dim())\n",
    "            )\n",
    "\n",
    "        if target.dim() != input.dim() - 1:\n",
    "            raise ValueError(\n",
    "                \"expected target dimension {} for input dimension {}, got {}\".format(\n",
    "                    input.dim() - 1, input.dim(), target.dim()\n",
    "                )\n",
    "            )\n",
    "\n",
    "        m = input.size(0)\n",
    "        probabilities = nn.functional.softmax(input[range(m), target], dim=0)\n",
    "        focal = self.alpha * (1 - probabilities).pow(self.gamma)\n",
    "        ce = nn.functional.cross_entropy(\n",
    "            input, target, reduction=\"none\"\n",
    "        )\n",
    "        loss = focal * ce\n",
    "\n",
    "        if self.reduction_op is not None:\n",
    "            return self.reduction_op(loss)\n",
    "        else:\n",
    "            return loss\n",
    "        \n",
    "    def forward_onehot(self, input, target):\n",
    "        if input.dim() != 2 and input.dim() != 4:\n",
    "            raise ValueError(\"expected input of size 4 or 2, got {}\".format(input.dim()))\n",
    "            \n",
    "        if target.dim() != 1 and target.dim() != 3:\n",
    "            raise ValueError(\"expected target of size 3 or 1, got {}\".format(target.dim()))\n",
    "            \n",
    "        target_onehot = to_onehot(target, input.size(1))\n",
    "            \n",
    "        m = input.size(0)\n",
    "        probabilities = torch.sum(target_onehot * F.softmax(input, dim=0), dim=1)\n",
    "        focal = self.alpha * (1 - probabilities).pow(self.gamma)\n",
    "        ce = F.cross_entropy(input, target, reduction=\"none\")\n",
    "        loss = focal * ce\n",
    "        \n",
    "        if self.reduction_op is not None:\n",
    "            return self.reduction_op(loss)\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(tensor, num_classes):    \n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    onehot = torch.zeros(tensor.size(0), num_classes, *tensor.size()[2:])\n",
    "    onehot.scatter_(1, tensor, 1)\n",
    "    \n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " tensor([1])\n",
      "Model out:\n",
      " tensor([[-100.,  100., -100.,  -50.]])\n",
      "Loss:\n",
      " tensor(0.)\n",
      "Onehot loss:\n",
      " tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "loss = FocalWithLogitsLoss()\n",
    "\n",
    "target = torch.Tensor([1]).long()\n",
    "out = torch.Tensor([[-100, 100, -100, -50]]).float()\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Model out:\\n\", out)\n",
    "print(\"Loss:\\n\", loss.forward(out, target))\n",
    "print(\"Onehot loss:\\n\", loss.forward_onehot(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " tensor([1, 0, 0])\n",
      "Model out:\n",
      " tensor([[-100.,  100., -100.,  -50.],\n",
      "        [-100., -100., -100.,   50.],\n",
      "        [ 100., -100., -100.,  -50.]])\n",
      "Loss:\n",
      " tensor(12.5000)\n",
      "Onehot loss:\n",
      " tensor(12.5000)\n"
     ]
    }
   ],
   "source": [
    "target = torch.Tensor([1, 0, 0]).long()\n",
    "out = torch.Tensor([[-100, 100, -100, -50], [-100, -100, -100, 50], [100, -100, -100, -50]]).float()\n",
    "print(\"Target:\\n\", target)\n",
    "print(\"Model out:\\n\", out)\n",
    "print(\"Loss:\\n\", loss.forward(out, target))\n",
    "print(\"Onehot loss:\\n\", loss.forward_onehot(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " torch.Size([2, 5, 5])\n",
      "Model out:\n",
      " torch.Size([2, 3, 5, 5])\n",
      "Loss:\n",
      " tensor(15.)\n",
      "Onehot loss:\n",
      " tensor(6.3750)\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(3, (2, 5, 5)).long()\n",
    "out = torch.randint(3, (2, 5, 5)).long()\n",
    "out = to_onehot(out, 3).float() * 100\n",
    "print(\"Target:\\n\", target.size())\n",
    "print(\"Model out:\\n\", out.size())\n",
    "print(\"Loss:\\n\", loss.forward(out, target))\n",
    "print(\"Onehot loss:\\n\", loss.forward_onehot(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:\n",
      " torch.Size([2, 5, 5])\n",
      "Model out:\n",
      " torch.Size([2, 3, 5, 5])\n",
      "Loss:\n",
      " tensor(0.)\n",
      "Onehot loss:\n",
      " tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(3, (2, 5, 5)).long()\n",
    "out = to_onehot(target, 3).float() * 100\n",
    "print(\"Target:\\n\", target.size())\n",
    "print(\"Model out:\\n\", out.size())\n",
    "print(\"Loss:\\n\", loss.forward(out, target))\n",
    "print(\"Onehot loss:\\n\", loss.forward_onehot(out, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.32 s ± 144 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "target = torch.randint(3, (5, 2048, 2048)).long()\n",
    "out = to_onehot(target, 3).float() * 100\n",
    "%timeit loss.forward(out, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.44 s ± 58.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit loss.forward_onehot(out, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one-hot solution is almost 2 times slower than the permute-view solution. Will use permute-view solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Airbus",
   "language": "python",
   "name": "airbus-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
